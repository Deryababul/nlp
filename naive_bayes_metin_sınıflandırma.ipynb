{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b6346f",
   "metadata": {},
   "source": [
    "# A Jupyter Notebook for Text Classification using Naive Bayes\n",
    "This notebook demonstrates how to perform text classification using the Naive Bayes algorithm. It includes steps for data preprocessing, vectorization, model training, evaluation, and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e41b8",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Import necessary libraries such as pandas, numpy, re, nltk, and scikit-learn modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ce5cd",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset\n",
    "Load the dataset into a pandas DataFrame and display the first few rows to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = {\n",
    "    \"Yorum\": [\n",
    "        \"Harika bir film, bayıldım!\",\n",
    "        \"Çok kötüydü, hiç beğenmedim.\",\n",
    "        \"Gerçekten mükemmeldi, tekrar izlerim.\",\n",
    "        \"Tam bir hayal kırıklığı, zaman kaybı.\",\n",
    "        \"Şahane bir oyunculuk, bayıldım!\",\n",
    "        \"Bu kadar kötü bir film izlemedim.\",\n",
    "        \"Senaryo çok etkileyiciydi, harika!\",\n",
    "        \"Berbat bir senaryo, rezalet!\",\n",
    "        \"Muhteşem bir yapım, herkese tavsiye ederim.\",\n",
    "        \"Sıkıcı ve anlamsızdı, hiç keyif almadım.\",\n",
    "        \"Tek kelimeyle harika, kesinlikle izlenmeli!\",\n",
    "        \"Tamamen vakit kaybı, hiç beğenmedim.\",\n",
    "        \"Filmdeki sahneler çok etkileyiciydi.\",\n",
    "        \"Hiç mantıklı değildi, boş bir filmdi.\",\n",
    "        \"Gerçekten çok beğendim, harikaydı!\",\n",
    "        \"Bunu izlediğime pişman oldum, berbat.\",\n",
    "        \"Film muhteşemdi, her anı mükemmeldi.\",\n",
    "        \"Senaryo çok basitti, sıkıldım.\",\n",
    "        \"İzlerken çok keyif aldım, tekrar izlerim.\",\n",
    "        \"Tam bir felaketti, param boşa gitti.\"\n",
    "    ],\n",
    "    \"Etiket\": [\"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\",\n",
    "               \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\",\n",
    "               \"Pozitif\", \"Negatif\", \"Pozitif\", \"Negatif\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbec5fd",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Define a function to clean the text data by converting to lowercase, removing punctuation, and filtering out stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Function\n",
    "def temizle(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    stop_words = set(stopwords.words('turkish'))  # Turkish stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['Temiz_Yorum'] = df['Yorum'].apply(temizle)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85664155",
   "metadata": {},
   "source": [
    "## Text Vectorization\n",
    "Use TfidfVectorizer to convert the cleaned text data into numerical feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93768090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization\n",
    "X = df['Temiz_Yorum']\n",
    "y = df['Etiket'].map({'Pozitif': 1, 'Negatif': 0})  # Convert labels to numeric\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a8baf",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Split the dataset into training and testing sets using train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0aeef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b5e22",
   "metadata": {},
   "source": [
    "## Train Naive Bayes Model\n",
    "Train a Multinomial Naive Bayes model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cea4f",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "Evaluate the model's performance on the test data using accuracy_score and classification_report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Doğruluk Oranı:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nSınıflandırma Raporu:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fc99a",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "Use the trained model to predict the sentiment of a new sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "yeni_yorum = [\"Senaryo çok basitti\"]\n",
    "yeni_yorum_tfidf = vectorizer.transform(yeni_yorum)\n",
    "tahmin = model.predict(yeni_yorum_tfidf)\n",
    "\n",
    "print(\"Tahmin:\", \"Pozitif\" if tahmin[0] == 1 else \"Negatif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
